{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Landmark Classification Project Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The \"deep-learning-landmark-classification\" project aims to classify famous landmarks using deep learning models. It employs both custom Convolutional Neural Networks (CNNs) and transfer learning techniques. This report details the workings of the models, compares different architectures, and presents the results. The model consists of 2 branches; the main (international) model is about the classification of 50 worldwide landmarks while the local model’s dataset consists of 20 Greek landmarks. The final goal here was to utilize the developed models for deployment in a real-world environment hence the “spot the spot” application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "\n",
    "The international model consists of 50 landmarks:\n",
    "\n",
    "- Haleakala National Park\n",
    "- Mount Rainier National Park\n",
    "- Ljubljana Castle\n",
    "- Dead Sea\n",
    "- Wroclaws Dwarves\n",
    "- London Olympic Stadium\n",
    "- Niagara Falls\n",
    "- Stonehenge\n",
    "- Grand Canyon\n",
    "- Golden Gate Bridge\n",
    "- Edinburgh Castle\n",
    "- Mount Rushmore National Memorial\n",
    "- Kantanagar Temple\n",
    "- Yellowstone National Park\n",
    "- Terminal Tower\n",
    "- Central Park\n",
    "- Eiffel Tower\n",
    "- Changdeokgung\n",
    "- Delicate Arch\n",
    "- Vienna City Hall\n",
    "- Matterhorn\n",
    "- Taj Mahal\n",
    "- Moscow Raceway\n",
    "- Externsteine\n",
    "- Soreq Cave\n",
    "- Banff National Park\n",
    "- Pont du Gard\n",
    "- Seattle Japanese Garden\n",
    "- Sydney Harbour Bridge\n",
    "- Petronas Towers\n",
    "- Brooklyn Bridge\n",
    "- Washington Monument\n",
    "- Hanging Temple\n",
    "- Sydney Opera House\n",
    "- Great Barrier Reef\n",
    "- Monumento a la Revolucion\n",
    "- Badlands National Park\n",
    "- Atomium\n",
    "- Forth Bridge\n",
    "- Gateway of India\n",
    "- Stockholm City Hall\n",
    "- Machu Picchu\n",
    "- Death Valley National Park\n",
    "- Gullfoss Falls\n",
    "- Trevi Fountain\n",
    "- Temple of Heaven\n",
    "- Great Wall of China\n",
    "- Prague Astronomical Clock\n",
    "- Whitby Abbey\n",
    "- Temple of Olympian Zeus\n",
    "\n",
    "All the images that were used for the international model were sourced from the Google Landmarks Dataset v2 ([Google Landmarks Dataset](https://github.com/cvdfoundation/google-landmark)).\n",
    "\n",
    "The local model dataset consists of images of 20 famous Greek landmarks:\n",
    "\n",
    "- Arch of Hadrian (Athens)\n",
    "- Bridge of Arta\n",
    "- Erechtheum\n",
    "- Fetiye Mosque\n",
    "- Lion Gate (Mycenae)\n",
    "- Meteora\n",
    "- Palace of the Grand Master of the Knights of Rhodes\n",
    "- Panathenaic Stadium\n",
    "- Parthenon\n",
    "- Portara\n",
    "- Sanctuary of Asclepius\n",
    "- Stoa of Attalus\n",
    "- Temple of Apollo in Delphi\n",
    "- Temple of Hephaestus in Athens\n",
    "- Temple of Poseidon Cape Sounion\n",
    "- Temple of Zeus\n",
    "- Theater of Epidaurus\n",
    "- Theatre of Herodes Atticus\n",
    "- Tower of the Winds\n",
    "- White Tower (Thessaloniki)\n",
    "\n",
    "All the images that were used for the local model were sourced from Wikimedia Commons, an online repository of free-use images, sound, and other media files. The photographs were downloaded using the scrapper defined in `wikimedia_scrapper.ipyb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "- **Resizing:** All images are resized to a uniform size.\n",
    "- **Normalization:** Pixel values are normalized.\n",
    "- **Augmentation:** Techniques like rotation, flipping, and zooming are applied to increase dataset diversity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom CNN Architecture\n",
    "\n",
    "The custom CNN architecture is defined in `LandMarkModel.py` and includes:\n",
    "\n",
    "- **Layers:**\n",
    "  - Multiple convolutional layers with ReLU activations and batch normalization.\n",
    "  - Pooling layers to reduce spatial dimensions.\n",
    "  - Fully connected (dense) layers for classification.\n",
    "  - Dropout layers for regularization to prevent overfitting.\n",
    "- **Implementation:** The `LandmarkCnnModel` class defines the model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning Architecture\n",
    "\n",
    "The transfer learning approach uses pre-trained models as a starting point, fine-tuning them for the specific task of landmark classification. The models used are:\n",
    "\n",
    "- **ResNet18, ResNet50, ResNet152:** These models are defined in `TransferModel.py` using the PyTorch `torchvision.models` library.\n",
    "- **Fine-Tuning:** The initial layers leverage pre-trained weights from the ImageNet dataset. The final layer that is added is trained on the landmark datasets specifically for 50 classes in the international model and 20 classes for the local model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Optimization\n",
    "\n",
    "- **Training Script:** `Training.py`\n",
    "- **Training Loop:** Includes functions for training the model for one epoch and for the entire training process.\n",
    "- **Plotting:** Utilizes `livelossplot` for real-time loss plotting.\n",
    "- **Optimization Script:** `Optimization.py`\n",
    "- **Hyperparameter Tuning:** Functions for optimizing learning rate, batch size, and other hyperparameters.\n",
    "- **Data Handling:** `Data.py`\n",
    "  - Data Loaders: Functions to create training, validation, and test data loaders with specified batch sizes and validation splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Export and Prediction\n",
    "\n",
    "- **Model Export:** `ModelExporter.py`\n",
    "  - Export Function: Function to save the trained model for inference.\n",
    "- **Prediction Script:** `PredictorWrapper.py`\n",
    "  - Predictor Class: A class that wraps the model and handles preprocessing and prediction.\n",
    "  - Confusion Matrix: A function to plot the confusion matrix to evaluate model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Comparison\n",
    "\n",
    "The results are compared based on accuracy, training time, and computational efficiency.\n",
    "\n",
    "| Model        | Accuracy@Local | Accuracy@International |\n",
    "|--------------|----------------|------------------------|\n",
    "| Custom CNN   | 81%            | 57%                    |\n",
    "| ResNet18     | 87%            | 76%                    |\n",
    "| ResNet50     | 90%            | 80%                    |\n",
    "| ResNet152    | 89%            | 80%                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Model Analysis\n",
    "\n",
    "**Custom CNNs:**\n",
    "- **Pros:** Flexibility in designing the architecture, control over every layer.\n",
    "- **Cons:** Requires more training time and computational resources, lower accuracy.\n",
    "\n",
    "**Transfer Learning:**\n",
    "- **Pros:** Leverages powerful features from pre-trained models, faster training, higher accuracy.\n",
    "- **Cons:** Limited flexibility in architecture design, dependency on pre-trained weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "All transfer learning models significantly outperformed our custom CNNs in terms of accuracy and training efficiency. Among the transfer learning models, ResNet50 demonstrated the greatest performance, but without significant difference between the other two. This highlights the effectiveness of using pre-trained models for complex image classification tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
